{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change integers to 32-bit floating point numbers\n",
    "X_train = X_train.astype('float32')  \n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# normalize the inputs to be in the range [0-1] instead of [0-255].\n",
    "X_train /= 255                       \n",
    "X_test /= 255\n",
    "\n",
    "# Modify classes to be in the one-hot format.\n",
    "nb_classes = 10 # number of digits\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "391/391 [==============================] - 48s 107ms/step - loss: 1.6317 - accuracy: 0.4085\n",
      "Epoch 2/25\n",
      "391/391 [==============================] - 49s 125ms/step - loss: 1.2657 - accuracy: 0.5483\n",
      "Epoch 3/25\n",
      "391/391 [==============================] - 54s 137ms/step - loss: 1.1040 - accuracy: 0.6078\n",
      "Epoch 4/25\n",
      "391/391 [==============================] - 54s 138ms/step - loss: 0.9871 - accuracy: 0.6517\n",
      "Epoch 5/25\n",
      "391/391 [==============================] - 56s 144ms/step - loss: 0.8798 - accuracy: 0.6877\n",
      "Epoch 6/25\n",
      "391/391 [==============================] - 54s 138ms/step - loss: 0.7921 - accuracy: 0.7185\n",
      "Epoch 7/25\n",
      "362/391 [==========================>...] - ETA: 4s - loss: 0.7083 - accuracy: 0.7498"
     ]
    }
   ],
   "source": [
    "# model is a linear stack of layers\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "# Summarize the built model\n",
    "#model.summary()\n",
    "\n",
    "# categorical cross-entropy is a loss function to comparing two probability distributions.\n",
    "# use the Adam optimizer for learning\n",
    "# The optimizer helps determine how quickly the model learns through gradient descent. \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Training\n",
    "model.fit(X_train, Y_train, batch_size=128, epochs=25, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 6s 13ms/step - loss: 1.2001 - accuracy: 0.6130\n",
      "Test loss: 1.2000609636306763\n",
      "Test accuracy: 0.6129999756813049\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "score = model.evaluate(X_test, Y_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train the model and get the history object\n",
    "history = model.fit(X_train, Y_train, batch_size=10, epochs=25, verbose=1)\n",
    "\n",
    "# Plot the loss function values for each epoch\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
